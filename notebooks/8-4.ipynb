{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dac16288-6310-4c78-8886-d5b2e4dc18a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Rodando experimento: LSTM_u50_d0.2_b32 ===\n",
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\guiga\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:199: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m39/39\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 46ms/step - loss: 0.0131 - val_loss: 0.0104\n",
      "Epoch 2/30\n",
      "\u001b[1m39/39\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 36ms/step - loss: 0.0020 - val_loss: 0.0013\n",
      "Epoch 3/30\n",
      "\u001b[1m39/39\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - loss: 0.0013 - val_loss: 0.0013\n",
      "Epoch 4/30\n",
      "\u001b[1m39/39\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.0013 - val_loss: 0.0016\n",
      "Epoch 5/30\n",
      "\u001b[1m39/39\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - loss: 0.0013 - val_loss: 0.0020\n",
      "Epoch 6/30\n",
      "\u001b[1m39/39\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 40ms/step - loss: 0.0011 - val_loss: 9.9266e-04\n",
      "Epoch 7/30\n",
      "\u001b[1m39/39\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - loss: 0.0011 - val_loss: 0.0013\n",
      "Epoch 8/30\n",
      "\u001b[1m39/39\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - loss: 0.0010 - val_loss: 0.0016\n",
      "Epoch 9/30\n",
      "\u001b[1m39/39\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - loss: 0.0010 - val_loss: 9.1914e-04\n",
      "Epoch 10/30\n",
      "\u001b[1m39/39\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 36ms/step - loss: 9.5002e-04 - val_loss: 8.5539e-04\n",
      "Epoch 11/30\n",
      "\u001b[1m39/39\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - loss: 8.4719e-04 - val_loss: 0.0023\n",
      "Epoch 12/30\n",
      "\u001b[1m39/39\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - loss: 9.1927e-04 - val_loss: 7.9433e-04\n",
      "Epoch 13/30\n",
      "\u001b[1m39/39\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - loss: 8.9546e-04 - val_loss: 8.0973e-04\n",
      "Epoch 14/30\n",
      "\u001b[1m39/39\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - loss: 8.5517e-04 - val_loss: 0.0015\n",
      "Epoch 15/30\n",
      "\u001b[1m39/39\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - loss: 8.1549e-04 - val_loss: 9.2997e-04\n",
      "Epoch 16/30\n",
      "\u001b[1m39/39\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - loss: 7.5759e-04 - val_loss: 9.1301e-04\n",
      "Epoch 17/30\n",
      "\u001b[1m39/39\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 7.0183e-04 - val_loss: 0.0014\n",
      "\n",
      "=== Rodando experimento: LSTM_u100_d0.3_b64 ===\n",
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\guiga\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:199: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m20/20\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 91ms/step - loss: 0.0107 - val_loss: 0.0154\n",
      "Epoch 2/30\n",
      "\u001b[1m20/20\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 69ms/step - loss: 0.0020 - val_loss: 0.0045\n",
      "Epoch 3/30\n",
      "\u001b[1m20/20\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 69ms/step - loss: 0.0015 - val_loss: 0.0024\n",
      "Epoch 4/30\n",
      "\u001b[1m20/20\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 75ms/step - loss: 0.0013 - val_loss: 0.0013\n",
      "Epoch 5/30\n",
      "\u001b[1m20/20\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 84ms/step - loss: 0.0011 - val_loss: 0.0014\n",
      "Epoch 6/30\n",
      "\u001b[1m20/20\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - loss: 9.9002e-04 - val_loss: 0.0017\n",
      "Epoch 7/30\n",
      "\u001b[1m20/20\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 63ms/step - loss: 0.0011 - val_loss: 0.0013\n",
      "Epoch 8/30\n",
      "\u001b[1m20/20\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 66ms/step - loss: 9.8537e-04 - val_loss: 0.0010\n",
      "Epoch 9/30\n",
      "\u001b[1m20/20\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 64ms/step - loss: 0.0010 - val_loss: 0.0013\n",
      "Epoch 10/30\n",
      "\u001b[1m20/20\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 68ms/step - loss: 8.9767e-04 - val_loss: 9.3139e-04\n",
      "Epoch 11/30\n",
      "\u001b[1m20/20\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 64ms/step - loss: 9.2467e-04 - val_loss: 9.9192e-04\n",
      "Epoch 12/30\n",
      "\u001b[1m20/20\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - loss: 8.8699e-04 - val_loss: 0.0018\n",
      "Epoch 13/30\n",
      "\u001b[1m20/20\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 72ms/step - loss: 8.4332e-04 - val_loss: 8.9054e-04\n",
      "Epoch 14/30\n",
      "\u001b[1m20/20\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 74ms/step - loss: 8.3680e-04 - val_loss: 0.0010\n",
      "Epoch 15/30\n",
      "\u001b[1m20/20\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 77ms/step - loss: 8.0915e-04 - val_loss: 8.7454e-04\n",
      "Epoch 16/30\n",
      "\u001b[1m20/20\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 71ms/step - loss: 7.7381e-04 - val_loss: 0.0011\n",
      "Epoch 17/30\n",
      "\u001b[1m20/20\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 79ms/step - loss: 7.4480e-04 - val_loss: 7.8210e-04\n",
      "Epoch 18/30\n",
      "\u001b[1m20/20\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 66ms/step - loss: 7.1850e-04 - val_loss: 9.2710e-04\n",
      "Epoch 19/30\n",
      "\u001b[1m20/20\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 65ms/step - loss: 7.2015e-04 - val_loss: 0.0010\n",
      "Epoch 20/30\n",
      "\u001b[1m20/20\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 66ms/step - loss: 7.0808e-04 - val_loss: 0.0010\n",
      "Epoch 21/30\n",
      "\u001b[1m20/20\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 62ms/step - loss: 7.4176e-04 - val_loss: 0.0015\n",
      "Epoch 22/30\n",
      "\u001b[1m20/20\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 66ms/step - loss: 6.8331e-04 - val_loss: 9.5433e-04\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x0000015A3B81B740> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "\n",
      "=== Rodando experimento: GRU_u50_d0.2_b32 ===\n",
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\guiga\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:199: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m39/39\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 48ms/step - loss: 0.0142 - val_loss: 0.0200\n",
      "Epoch 2/30\n",
      "\u001b[1m39/39\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - loss: 0.0020 - val_loss: 7.1421e-04\n",
      "Epoch 3/30\n",
      "\u001b[1m39/39\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - loss: 0.0011 - val_loss: 7.0593e-04\n",
      "Epoch 4/30\n",
      "\u001b[1m39/39\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - loss: 9.0761e-04 - val_loss: 7.7797e-04\n",
      "Epoch 5/30\n",
      "\u001b[1m39/39\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - loss: 9.1885e-04 - val_loss: 8.1429e-04\n",
      "Epoch 6/30\n",
      "\u001b[1m39/39\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - loss: 9.0844e-04 - val_loss: 5.4989e-04\n",
      "Epoch 7/30\n",
      "\u001b[1m39/39\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - loss: 7.7455e-04 - val_loss: 5.9552e-04\n",
      "Epoch 8/30\n",
      "\u001b[1m39/39\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - loss: 7.3881e-04 - val_loss: 0.0012\n",
      "Epoch 9/30\n",
      "\u001b[1m39/39\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - loss: 7.8898e-04 - val_loss: 9.0848e-04\n",
      "Epoch 10/30\n",
      "\u001b[1m39/39\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 36ms/step - loss: 7.3113e-04 - val_loss: 7.3179e-04\n",
      "Epoch 11/30\n",
      "\u001b[1m39/39\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - loss: 6.6360e-04 - val_loss: 7.0015e-04\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x0000015A3CE3C720> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "\n",
      "=== Rodando experimento: GRU_u100_d0.3_b64 ===\n",
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\guiga\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:199: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m20/20\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 94ms/step - loss: 0.0171 - val_loss: 0.0177\n",
      "Epoch 2/30\n",
      "\u001b[1m20/20\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 63ms/step - loss: 0.0033 - val_loss: 0.0021\n",
      "Epoch 3/30\n",
      "\u001b[1m20/20\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 69ms/step - loss: 0.0012 - val_loss: 7.7227e-04\n",
      "Epoch 4/30\n",
      "\u001b[1m20/20\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 68ms/step - loss: 9.1996e-04 - val_loss: 6.2548e-04\n",
      "Epoch 5/30\n",
      "\u001b[1m20/20\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 70ms/step - loss: 8.0429e-04 - val_loss: 7.3612e-04\n",
      "Epoch 6/30\n",
      "\u001b[1m20/20\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 69ms/step - loss: 8.3623e-04 - val_loss: 5.7639e-04\n",
      "Epoch 7/30\n",
      "\u001b[1m20/20\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 66ms/step - loss: 8.2772e-04 - val_loss: 7.4010e-04\n",
      "Epoch 8/30\n",
      "\u001b[1m20/20\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 70ms/step - loss: 7.1594e-04 - val_loss: 7.4122e-04\n",
      "Epoch 9/30\n",
      "\u001b[1m20/20\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 83ms/step - loss: 7.5435e-04 - val_loss: 5.3968e-04\n",
      "Epoch 10/30\n",
      "\u001b[1m20/20\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 70ms/step - loss: 7.0363e-04 - val_loss: 5.1722e-04\n",
      "Epoch 11/30\n",
      "\u001b[1m20/20\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 65ms/step - loss: 6.9745e-04 - val_loss: 6.3666e-04\n",
      "Epoch 12/30\n",
      "\u001b[1m20/20\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 62ms/step - loss: 6.9708e-04 - val_loss: 5.1495e-04\n",
      "Epoch 13/30\n",
      "\u001b[1m20/20\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 63ms/step - loss: 6.3150e-04 - val_loss: 4.7477e-04\n",
      "Epoch 14/30\n",
      "\u001b[1m20/20\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 63ms/step - loss: 6.2516e-04 - val_loss: 5.3008e-04\n",
      "Epoch 15/30\n",
      "\u001b[1m20/20\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 63ms/step - loss: 6.2780e-04 - val_loss: 7.7884e-04\n",
      "Epoch 16/30\n",
      "\u001b[1m20/20\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 70ms/step - loss: 6.0290e-04 - val_loss: 5.0192e-04\n",
      "Epoch 17/30\n",
      "\u001b[1m20/20\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 66ms/step - loss: 5.5129e-04 - val_loss: 5.2963e-04\n",
      "Epoch 18/30\n",
      "\u001b[1m20/20\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 83ms/step - loss: 5.4718e-04 - val_loss: 4.4785e-04\n",
      "Epoch 19/30\n",
      "\u001b[1m20/20\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - loss: 5.7151e-04 - val_loss: 4.4272e-04\n",
      "Epoch 20/30\n",
      "\u001b[1m20/20\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 5.7760e-04 - val_loss: 5.8844e-04\n",
      "Epoch 21/30\n",
      "\u001b[1m20/20\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 66ms/step - loss: 5.6918e-04 - val_loss: 4.4357e-04\n",
      "Epoch 22/30\n",
      "\u001b[1m20/20\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 63ms/step - loss: 5.1748e-04 - val_loss: 4.2030e-04\n",
      "Epoch 23/30\n",
      "\u001b[1m20/20\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 68ms/step - loss: 4.8656e-04 - val_loss: 4.1464e-04\n",
      "Epoch 24/30\n",
      "\u001b[1m20/20\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 66ms/step - loss: 5.1749e-04 - val_loss: 4.4425e-04\n",
      "Epoch 25/30\n",
      "\u001b[1m20/20\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 58ms/step - loss: 4.9441e-04 - val_loss: 4.1486e-04\n",
      "Epoch 26/30\n",
      "\u001b[1m20/20\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 68ms/step - loss: 4.9365e-04 - val_loss: 4.3527e-04\n",
      "Epoch 27/30\n",
      "\u001b[1m20/20\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 76ms/step - loss: 4.7461e-04 - val_loss: 4.2770e-04\n",
      "Epoch 28/30\n",
      "\u001b[1m20/20\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 65ms/step - loss: 4.9766e-04 - val_loss: 6.9046e-04\n",
      "\n",
      "ğŸ“Š Ranking final dos modelos:\n",
      "                model      MAPE          MAE         RMSE\n",
      "3   GRU_u100_d0.3_b64  2.109388  1972.807998  2611.020352\n",
      "2    GRU_u50_d0.2_b32  2.404621  2249.352843  2934.067115\n",
      "0   LSTM_u50_d0.2_b32  2.654398  2485.191737  3282.326496\n",
      "1  LSTM_u100_d0.3_b64  2.774489  2618.347325  3370.052471\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "\n",
    "from keras.models import Sequential, load_model\n",
    "from keras.layers import LSTM, GRU, Dense, Dropout\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "\n",
    "# =========================\n",
    "# 1. Carregar dados\n",
    "# =========================\n",
    "file_path = 'data/btc_limpo.csv'\n",
    "df = pd.read_csv(file_path, parse_dates=['Date'], index_col='Date')\n",
    "\n",
    "prices = df['Close'].values.reshape(-1,1)\n",
    "\n",
    "scaler = MinMaxScaler(feature_range=(0,1))\n",
    "prices_scaled = scaler.fit_transform(prices)\n",
    "\n",
    "# =========================\n",
    "# 2. FunÃ§Ã£o para criar sequÃªncias\n",
    "# =========================\n",
    "def create_sequences(data, seq_len=60):\n",
    "    X, y = [], []\n",
    "    for i in range(seq_len, len(data)):\n",
    "        X.append(data[i-seq_len:i, 0])\n",
    "        y.append(data[i, 0])\n",
    "    return np.array(X), np.array(y)\n",
    "\n",
    "SEQ_LEN = 60\n",
    "X, y = create_sequences(prices_scaled, SEQ_LEN)\n",
    "X = np.expand_dims(X, axis=-1)\n",
    "\n",
    "# dividir treino/val/teste (70/20/10)\n",
    "split1 = int(0.7*len(X))\n",
    "split2 = int(0.9*len(X))\n",
    "\n",
    "X_train, y_train = X[:split1], y[:split1]\n",
    "X_val, y_val = X[split1:split2], y[split1:split2]\n",
    "X_test, y_test = X[split2:], y[split2:]\n",
    "\n",
    "# =========================\n",
    "# 3. FunÃ§Ãµes de modelos\n",
    "# =========================\n",
    "def build_lstm(units=50, dropout=0.2):\n",
    "    model = Sequential([\n",
    "        LSTM(units, return_sequences=False, input_shape=(SEQ_LEN,1)),\n",
    "        Dropout(dropout),\n",
    "        Dense(1)\n",
    "    ])\n",
    "    model.compile(optimizer='adam', loss='mse')\n",
    "    return model\n",
    "\n",
    "def build_gru(units=50, dropout=0.2):\n",
    "    model = Sequential([\n",
    "        GRU(units, return_sequences=False, input_shape=(SEQ_LEN,1)),\n",
    "        Dropout(dropout),\n",
    "        Dense(1)\n",
    "    ])\n",
    "    model.compile(optimizer='adam', loss='mse')\n",
    "    return model\n",
    "\n",
    "# =========================\n",
    "# 4. Grid de Experimentos\n",
    "# =========================\n",
    "experiments = []\n",
    "\n",
    "param_grid = [\n",
    "    {'type': 'LSTM', 'units': 50, 'dropout': 0.2, 'batch_size': 32},\n",
    "    {'type': 'LSTM', 'units': 100, 'dropout': 0.3, 'batch_size': 64},\n",
    "    {'type': 'GRU', 'units': 50, 'dropout': 0.2, 'batch_size': 32},\n",
    "    {'type': 'GRU', 'units': 100, 'dropout': 0.3, 'batch_size': 64},\n",
    "]\n",
    "\n",
    "results_dir = Path('results')\n",
    "outputs_dir = Path('outputs')\n",
    "results_dir.mkdir(exist_ok=True)\n",
    "outputs_dir.mkdir(exist_ok=True)\n",
    "\n",
    "for params in param_grid:\n",
    "    model_name = f\"{params['type']}_u{params['units']}_d{params['dropout']}_b{params['batch_size']}\"\n",
    "    print(f\"\\n=== Rodando experimento: {model_name} ===\")\n",
    "\n",
    "    if params['type'] == 'LSTM':\n",
    "        model = build_lstm(params['units'], params['dropout'])\n",
    "    else:\n",
    "        model = build_gru(params['units'], params['dropout'])\n",
    "\n",
    "    ckpt_path = results_dir / f\"{model_name}.keras\"\n",
    "\n",
    "    callbacks = [\n",
    "        EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True),\n",
    "        ModelCheckpoint(filepath=str(ckpt_path), monitor='val_loss', save_best_only=True)\n",
    "    ]\n",
    "\n",
    "    history = model.fit(\n",
    "        X_train, y_train,\n",
    "        validation_data=(X_val, y_val),\n",
    "        epochs=30,\n",
    "        batch_size=params['batch_size'],\n",
    "        callbacks=callbacks,\n",
    "        verbose=1\n",
    "    )\n",
    "\n",
    "    # carregar melhor modelo\n",
    "    model = load_model(str(ckpt_path))\n",
    "\n",
    "    # avaliaÃ§Ã£o no teste\n",
    "    y_pred_scaled = model.predict(X_test, verbose=0).flatten()\n",
    "    y_pred = scaler.inverse_transform(y_pred_scaled.reshape(-1,1)).flatten()\n",
    "    y_true = scaler.inverse_transform(y_test.reshape(-1,1)).flatten()\n",
    "\n",
    "    mape = np.mean(np.abs((y_true - y_pred) / y_true)) * 100\n",
    "    mae = mean_absolute_error(y_true, y_pred)\n",
    "    rmse = np.sqrt(mean_squared_error(y_true, y_pred))\n",
    "\n",
    "    experiments.append({\n",
    "        'model': model_name,\n",
    "        'MAPE': mape,\n",
    "        'MAE': mae,\n",
    "        'RMSE': rmse\n",
    "    })\n",
    "\n",
    "    # salvar grÃ¡fico\n",
    "    plt.figure(figsize=(10,5))\n",
    "    plt.plot(y_true, label='Real')\n",
    "    plt.plot(y_pred, label='Previsto')\n",
    "    plt.title(f\"{model_name} - PrevisÃ£o no Teste\")\n",
    "    plt.legend()\n",
    "    plt.savefig(outputs_dir / f\"{model_name}_forecast.png\")\n",
    "    plt.close()\n",
    "\n",
    "# =========================\n",
    "# 5. Resultados finais\n",
    "# =========================\n",
    "results_df = pd.DataFrame(experiments)\n",
    "results_df = results_df.sort_values(by='MAPE')\n",
    "\n",
    "print(\"\\nğŸ“Š Ranking final dos modelos:\")\n",
    "print(results_df)\n",
    "\n",
    "results_df.to_csv(results_dir / 'comparacao_0610.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "233eb4fa-8718-40c3-8a69-2b239c6bc78d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
